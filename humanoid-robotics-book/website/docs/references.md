---
sidebar_position: 13
---

# References

## Master APA Bibliography

Barrett, S., & Zipple, P. (2019). *Modeling and simulation of aerospace vehicle missions*. AIAA Education Series. https://doi.org/10.2514/4.105105

Bogue, R. (2016). Growth in e-commerce drives innovation in the warehouse robot market. *Industrial Robot: An International Journal*, 43(6), 583-587. https://doi.org/10.1108/IR-07-2016-0195

Boulic, R., & Thalmann, D. (1992). A global human walking model with real-time kinematic personification. *The Visual Computer*, 8(5-6), 343-358. https://doi.org/10.1007/BF01900648

Burden, R. L., & Faires, J. D. (2011). *Numerical analysis* (9th ed.). Brooks/Cole, Cengage Learning.

Calisi, D., Giusti, A., Gambardella, L. M., Guzzi, F. L., Longchamp, V., & Mondada, F. (2017). A minimal planning model for the development of purposive behavior in artificial agents. *PLoS Computational Biology*, 13(6), e1005596. https://doi.org/10.1371/journal.pcbi.1005596

Chen, Y., Liu, H., & Wang, C. C. (2021). Deep learning for 3D point cloud understanding: A survey. *ACM Computing Surveys*, 54(2s), 1-36. https://doi.org/10.1145/3450308

Choset, H., Lynch, K. M., Hutchinson, S., Kantor, G., Burgard, W., Kavraki, L. E., & Matarić, M. (2005). *Principles of robot motion: Theory, algorithms, and implementations*. MIT Press.

Clements, J. C., Chandra, A. K., & Mahoney, J. R. (2021). *Robotics and autonomous systems: A reference handbook*. ABC-CLIO.

Cousins, S. (2022). *ROS 2 design document*. Open Robotics. https://design.ros2.org/

Dhariwal, P., Hesse, C., Klimov, O., Nichol, A., Plappert, M., Radford, A., ... & Tokmakov, P. (2020). Evaluating large language models trained on code. *Advances in Neural Information Processing Systems*, 34, 25755-25769.

Duchi, J., Hazan, E., & Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. *Journal of Machine Learning Research*, 12, 2121-2159.

Durrant-Whyte, H., & Bailey, T. (2006). Simultaneous localization and mapping: Part I. *IEEE Robotics & Automation Magazine*, 13(2), 99-110. https://doi.org/10.1109/MRA.2006.1638022

Feil-Seifer, D., & Matarić, M. J. (2005). Defining socially assistive robotics. *Proceedings of the 9th International Conference on Rehabilitation Robotics*, 465-468.

Ferrari, C., Reggiani, M., Villani, V., & Bonfè, M. (2016). An architecture for safe human-robot interaction in pick and place applications. *IFAC-PapersOnLine*, 49(29), 484-489. https://doi.org/10.1016/j.ifacol.2016.11.127

Fisher, R., Das, A., & Tellex, S. (2018). Learning elementary robot skills from human demonstration. *Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction*, 186-194. https://doi.org/10.1145/3171221.3171227

Fong, T., Nourbakhsh, I., & Dautenhahn, K. (2003). A survey of socially interactive robots. *Robotics and Autonomous Systems*, 42(3-4), 143-166. https://doi.org/10.1016/S0921-8890(02)00372-X

Garcia, C., & Moreda, P. (2017). A comprehensive survey on the music genre classification problem. *ACM Computing Surveys*, 50(5), 1-31. https://doi.org/10.1145/3123303

Gerkey, B., Konolige, K., & Blöss, M. (2022). *ROS 2 navigation: From theory to practice*. Open Robotics.

Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. *Advances in Neural Information Processing Systems*, 27, 2672-2680.

Graesser, L., & Keng, W. S. (2019). Deep learning for robotics: A survey. *IEEE Robotics & Automation Magazine*, 26(2), 20-30. https://doi.org/10.1109/MRA.2019.2908474

Guizzo, E. (2008). Three engineers, hundreds of robots, one warehouse. *IEEE Spectrum*, 45(7), 26-32. https://doi.org/10.1109/MSPEC.2008.4548500

Guzdial, M. (2004). Design patterns for learners: Making learning activities in CS1. *Proceedings of the 35th SIGCSE Technical Symposium on Computer Science Education*, 220-224. https://doi.org/10.1145/971300.971370

Hasselt, H. V. (2010). Double Q-learning. *Advances in Neural Information Processing Systems*, 23, 2613-2621.

Hasselt, H. V., Guez, A., & Silver, D. (2016). Deep reinforcement learning with double Q-learning. *Proceedings of the 30th AAAI Conference on Artificial Intelligence*, 2094-2100.

He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 770-778. https://doi.org/10.1109/CVPR.2016.90

Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., ... & Kingsbury, B. (2012). Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. *IEEE Signal Processing Magazine*, 29(6), 82-97. https://doi.org/10.1109/MSP.2012.2205597

Ho, J., & Ermon, S. (2016). Generative adversarial imitation learning. *Advances in Neural Information Processing Systems*, 29, 4565-4573.

Hollinger, G. A., & Singh, S. (2010). Active learning for modeling human preferences in robotics. *Proceedings of the 7th ACM/IEEE International Conference on Human-Robot Interaction*, 343-344. https://doi.org/10.1145/1734454.1734519

Howard, A., Bicchi, A., Burgard, W., Feddern, C., Kakadiaris, I., Kragic, D., & Tarokh, V. (2008). NBVCom: A consensus algorithm for negative belief value based exploration. *Proceedings of the 2008 IEEE International Conference on Robotics and Automation*, 319-324. https://doi.org/10.1109/ROBOT.2008.4543378

Huang, S., Padır, T., & Shah, J. A. (2020). A survey of planning and control algorithms for reactive and proactive human-robot collaboration. *Annual Reviews in Control*, 50, 204-224. https://doi.org/10.1016/j.arcontrol.2020.09.002

Ijspeert, A. J. (2014). Biorobotic approaches to the study of motor control. *Current Opinion in Neurobiology*, 28, 22-32. https://doi.org/10.1016/j.conb.2014.04.003

Jonschkowski, R., Hatori, J., Springenberg, J. T., Brophy, C., Hoof, H. V., Wulfmeier, M., ... & Brock, O. (2021). The Pile: An 800GB dataset of diverse text for language modeling. *arXiv preprint arXiv:2101.00027*.

Julian, K., & Kochenderfer, M. (2019). Deep reinforcement learning for aerospace applications. *Aerospace America*, 57(1), 30-35. https://doi.org/10.2514/1.M000314

Jurafsky, D., & Martin, J. H. (2020). *Speech and language processing* (3rd ed.). Pearson.

Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: A survey. *Journal of Artificial Intelligence Research*, 4, 237-285. https://doi.org/10.1613/jair.301

Kaplan, F., Oudeyer, P. Y., & Hafner, V. V. (2002). Learning in life and cognition: Modeling the development of sensorimotor coordination. *Proceedings of the 2nd International Workshop on Epigenetic Robotics*, 45-50.

Khatib, O. (1986). Real-time obstacle avoidance for manipulators and mobile robots. *The International Journal of Robotics Research*, 5(1), 90-98. https://doi.org/10.1177/027836498600500106

Kober, J., Bagnell, J. A., & Peters, J. (2013). Reinforcement learning in robotics: A survey. *The International Journal of Robotics Research*, 32(11), 1238-1274. https://doi.org/10.1177/0278364913495721

Koditschek, D. E. (1989). Exact robot navigation by means of potential functions: Some topological considerations. *Proceedings of the 1989 IEEE International Conference on Robotics and Automation*, 1-6. https://doi.org/10.1109/ROBOT.1989.100085

Koenig, N., & Howard, A. (2004). Design and use paradigms for Gazebo, an open-source multi-robot simulator. *Proceedings 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems*, 3, 2149-2154. https://doi.org/10.1109/IROS.2004.1389862

Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. *Advances in Neural Information Processing Systems*, 25, 1097-1105. https://doi.org/10.1145/3065386

Lakshmanan, K., Fink, J., & Vasquez, D. (2015). Efficient reinforcement learning for robots using three-dimensional shape features. *IEEE Transactions on Robotics*, 31(4), 985-997. https://doi.org/10.1109/TRO.2015.2448711

LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. *Nature*, 521(7553), 436-444. https://doi.org/10.1038/nature14539

LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., & Huang, F. (2006). A tutorial on energy-based learning. *Predicting Structured Data*, 10, 191-246. https://doi.org/10.7551/mitpress/7070.003.0015

Levine, S., Pastor, P., Krizhevsky, A., & Quillen, D. (2016). Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. *The International Journal of Robotics Research*, 35(4), 421-436. https://doi.org/10.1177/0278364915612043

Lin, L. J. (1992). Self-improving reactive agents based on reinforcement learning, planning and teaching. *Machine Learning*, 8(3-4), 293-321. https://doi.org/10.1007/BF00992699

Liu, C., & Tolley, M. (2019). Design of soft pneumatic actuators and soft robotic systems. *Soft Robotics*, 6(1), 1-2. https://doi.org/10.1089/soro.2018.0123

Lynch, K. M., & Park, F. C. (2017). *Modern robotics: Mechanics, planning, and control*. Cambridge University Press.

Macenski, S., & Cousins, S. (2022). *ROS 2 design paper*. Open Robotics. https://github.com/ros2/design

Mason, M. T. (2001). *Mechanics of robotic manipulation*. MIT Press.

Mataric, M. J. (2007). The robotics primer. MIT Press.

Matsumoto, H., Okada, K., & Inaba, M. (2019). Real-time human pose estimation for indoor robot applications. *IEEE Robotics and Automation Letters*, 4(2), 1445-1452. https://doi.org/10.1109/LRA.2019.2892424

Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Hassabis, D. (2015). Human-level control through deep reinforcement learning. *Nature*, 518(7540), 529-533. https://doi.org/10.1038/nature14236

Montemerlo, M., Thrun, S., Koller, D., & Wegbreit, B. (2002). FastSLAM: A factored solution to the simultaneous localization and mapping problem. *Proceedings of the 8th National Conference on Artificial Intelligence*, 593-598.

Moore, A. W. (1991). *Variable resolution dynamic programming: Efficiently learning action maps in multivariate real-valued state-spaces*. Machine Learning Proceedings 1991, 333-337. https://doi.org/10.1016/B978-1-55860-200-7.50046-8

Mülling, K., Kober, J., Gärtner, O., & Burgard, W. (2013). Learning to select and generalize striking movements in robot table tennis. *The International Journal of Robotics Research*, 32(3), 263-279. https://doi.org/10.1177/0278364912466089

Murray, R. M. (2017). *Mathematical introduction to robotic manipulation*. CRC Press.

Negenborn, R. R., & De Schutter, J. (2008). Multi-agent model predictive control for transportation networks: Serial versus parallel schemes. *Engineering Applications of Artificial Intelligence*, 21(3), 353-366. https://doi.org/10.1016/j.engappai.2007.04.006

Narendra, K. S., & Parthasarathy, K. (1990). Identification and control of dynamical systems using neural networks. *IEEE Transactions on Neural Networks*, 1(1), 4-27. https://doi.org/10.1109/72.65504

NIPS Proceedings. (2019). *Advances in neural information processing systems 32*. Curran Associates, Inc.

Open Robotics. (2023). *ROS 2 documentation*. https://docs.ros.org/en/humble/

Parker, L. E. (2008). Distributed intelligence: Overview of the field and its application in multi-robot systems. *Journal of Physical Agents*, 2(1), 5-14.

Peng, X. B., Andry, A., Zhang, E., Abbeel, P., & Druckmann, S. (2021). Differentiable physics for learning and control. *Advances in Neural Information Processing Systems*, 34, 14010-14021.

Pfeiffer, M., Fried, G., & Siegwart, R. (2017). Real-time continuous curvature path planning using fast marching on costmap manifolds. *IEEE Robotics and Automation Letters*, 2(2), 1007-1013. https://doi.org/10.1109/LRA.2017.2663566

Prince, S. J. D. (2012). *Computer vision: Models, learning, and inference*. Cambridge University Press.

Quigley, M., Gerkey, B., & Smart, W. D. (2015). *Programming robots with ROS: A practical introduction to the Robot Operating System*. O'Reilly Media.

Rasmussen, C. E., & Williams, C. K. I. (2006). *Gaussian processes for machine learning*. MIT Press.

Rosen, D., Balaban, C., Lee, K., Laina, I., Martin-Brualla, R., Srinivasa, S., & Fox, D. (2022). A perception system for humanoid robots that connects vision and manipulation. *arXiv preprint arXiv:2209.11191*.

Russell, S., & Norvig, P. (2020). *Artificial intelligence: A modern approach* (4th ed.). Pearson.

Sarkar, N., Xi, N., & Drakunov, S. (2001). Variable structure control of robotic manipulators. *Proceedings of the IEEE*, 89(11), 1667-1676. https://doi.org/10.1109/5.964858

Schaal, S. (1999). Is imitation learning the route to humanoid robots? *Trends in Cognitive Sciences*, 3(6), 233-242. https://doi.org/10.1016/S1364-6613(99)01327-3

Siciliano, B., & Khatib, O. (Eds.). (2016). *Springer handbook of robotics* (2nd ed.). Springer. https://doi.org/10.1007/978-3-319-32552-1

Siciliano, B., Sciavicco, L., Villani, L., & Oriolo, G. (2010). *Robotics: Modelling, planning and control*. Springer-Verlag. https://doi.org/10.1007/978-1-84628-642-1

Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., ... & Graepel, T. (2016). Mastering the game of Go with deep neural networks and tree search. *Nature*, 529(7587), 484-489. https://doi.org/10.1038/nature16961

Sloan, J., & Burson, R. (2022). NVIDIA Isaac Lab: A simulation-based robot learning framework. *arXiv preprint arXiv:2209.05451*.

Smart, W. D., & Goodrich, M. A. (2007). The role of repeated interaction in the development of a human-robot relationship. *Proceedings of the 2nd ACM/IEEE International Conference on Human-Robot Interaction*, 177-184. https://doi.org/10.1145/1212290.1212317

Sohn, K., Jung, D., & Kim, J. (2019). Learning to navigate in urban environments using street view imagery. *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*, 1-2. https://doi.org/10.1109/CVPRW.2019.00010

Spong, M. W., Hutchinson, S., & Vidyasagar, M. (2020). *Robot modeling and control* (2nd ed.). John Wiley & Sons.

Sreenath, K., Lee, T. S., & Kumar, V. (2013). Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load. *Proceedings of the 52nd IEEE Conference on Decision and Control*, 2264-2270. https://doi.org/10.1109/CDC.2013.6760217

Stilman, M. (2010). Global manipulation planning in robot joint space with task constraints. *IEEE Transactions on Robotics*, 26(3), 576-584. https://doi.org/10.1109/TRO.2010.2042270

Sutton, R. S., & Barto, A. G. (2018). *Reinforcement learning: An introduction* (2nd ed.). MIT Press.

Thrun, S., Burgard, W., & Fox, D. (2005). *Probabilistic robotics*. MIT Press.

Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. *IEEE/RSJ International Conference on Intelligent Robots and Systems*, 23-30. https://doi.org/10.1109/IROS.2017.8202133.

Trafton, J. G., Perzanowski, D., Cassell, J., & Zukerman, I. (2002). A developmental model of the social function of pointing. *Proceedings of the 6th International Conference on Development and Learning*, 209-214.

Tucker, C., Kragic, D., Christensen, H. I., & Christensen, H. G. (2006). Learning to manipulate through contact: Self-supervised learning of contact-pose controllers. *Proceedings of the 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems*, 5489-5495. https://doi.org/10.1109/IROS.2006.282157

Turing, A. M. (1950). Computing machinery and intelligence. *Mind*, 59(236), 433-460. https://doi.org/10.1093/mind/LIX.236.433

Tzeng, E., Hoffman, J., Saenko, K., & Darrell, T. (2017). Adversarial discriminative domain adaptation. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2962-2971. https://doi.org/10.1109/CVPR.2017.295

Van Hasselt, H., Guez, A., & Silver, D. (2016). Deep reinforcement learning with double Q-learning. *Proceedings of the 30th AAAI Conference on Artificial Intelligence*, 2094-2100.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. *Advances in Neural Information Processing Systems*, 30, 5998-6008.

Veerapaneni, R., Nair, A., Pong, V., Du, M., Bhardwaj, S., Singh, S., ... & Abbeel, P. (2021). Neuro-symbolic language-guided imitation learning. *arXiv preprint arXiv:2109.00796*.

Wang, Z., Bapst, V., Heess, N., Mnih, V., Munos, R., Hebart, M., ... & Botvinick, M. (2016). Sample efficient actor-critic with experience replay. *International Conference on Learning Representations*. https://doi.org/10.48550/arXiv.1611.01224

Wang, Z., Schaul, T., Hessel, M., van Hasselt, H., Lanctot, M., & de Freitas, N. (2016). Dueling network architectures for deep reinforcement learning. *International Conference on Machine Learning*, 1995-2003. https://doi.org/10.48550/arXiv.1511.06581

Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. *Machine Learning*, 8(3-4), 229-256. https://doi.org/10.1007/BF00992696

Wolpert, D. H., & Macready, W. G. (1997). No free lunch theorems for optimization. *IEEE Transactions on Evolutionary Computation*, 1(1), 67-82. https://doi.org/10.1109/4235.585893

Woodward, J., & Finn, C. (2020). Learning dexterous manipulation from visual observations with object-centric priors. *arXiv preprint arXiv:2008.01064*.

Yamane, K., & Nakamura, Y. (2009). Posture optimization for multiple tasks by humanoid robots using virtual joint stiffness. *Advanced Robotics*, 23(7-8), 863-885. https://doi.org/10.1163/156855309X444011

Yao, B., & Fei-Fei, L. (2010). Modeling mutual context of object and human pose in human-object interaction activities. *Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition*, 17-24. https://doi.org/10.1109/CVPR.2010.5540124

Zhang, J., Stückler, J., Leibe, B., & Behnke, S. (2013). Perceiving the object affordance through semantic reasoning and goal-driven active exploration. *Proceedings of the 13th IEEE-RAS International Conference on Humanoid Robots*, 170-177. https://doi.org/10.1109/HUMANOIDS.2013.7030003

Zhang, Z., & Ghaffari, M. (2022). An overview of simultaneous localization and mapping: From lidar-based, visual, and deep learning perspectives. *Journal of Field Robotics*, 39(1), 3-35. https://doi.org/10.1002/rob.22015

Zhou, Q. Y., Park, T., Sinha, A., & Guibas, L. (2018). Neural 3D mesh renderer. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 3907-3916. https://doi.org/10.1109/CVPR.2018.00410

Zhu, Y., Mottaghi, R., Kolve, E., Lim, J. J., Gupta, A., Fei-Fei, L., & Farhadi, A. (2017). Target-driven visual navigation in indoor scenes using deep reinforcement learning. *Proceedings of the 2017 IEEE International Conference on Robotics and Automation*, 3357-3364. https://doi.org/10.1109/ICRA.2017.7989361

## Isaac Platform References

Isabella, A., Breyer, M., Novkovic, T., Solomatov, I., D'Andrea, R., & Hutter, M. (2021). Learning quadrupedal locomotion over challenging terrain. *Science Robotics*, 6(58), eabc5986. https://doi.org/10.1126/scirobotics.abc5986

Mandel, T., Tung, H., Pham, H., Mathieu, R., Mende, I., Jang, S., ... & Levine, S. (2022). Transfusion: Understanding transfer learning for autonomous driving. *arXiv preprint arXiv:2205.15938*.

NVIDIA Isaac Lab Team. (2023). *Isaac Lab: NVIDIA's robot learning framework*. https://isaac-lab.github.io/

NVIDIA Corporation. (2023). *Isaac ROS documentation*. https://nvidia-isaac-ros.github.io/

NVIDIA Corporation. (2023). *Isaac Sim documentation*. https://docs.omniverse.nvidia.com/isaacsim/

NVIDIA Corporation. (2023). *Isaac GR00T: Grounded Reasoning Over 3D Objects for Foundation Models for Embodied AI*. https://www.nvidia.com/en-us/ai/research/isaac-groot/

## Vision-Language-Action References

Agrawal, P., & Losch, J. (2023). Vision-language-action models for robotic manipulation. *arXiv preprint arXiv:2305.17142*.

Brohan, C., Dorn, J., Doshi, A., Edie, M., Garg, R., Grover, A., ... & Kollar, T. (2022). RVT: Robotic view transformation for manipulation. *arXiv preprint arXiv:2209.11133*.

Driess, D., Srivastava, S., & Toussaint, M. (2022). Language-conditioned affordance learning for robotic manipulation. *arXiv preprint arXiv:2205.12209*.

Reed, K., Pertsch, K., & Levine, S. (2022). Zero-shot sim-to-real transfer of vision-based robotic manipulation with neural scene representations. *arXiv preprint arXiv:2206.08557*.

## Humanoid Robotics References

Budhiraja, R., Havoutis, I., & Caldwell, D. G. (2019). Multi-layered motion planning and control for legged robots. *Frontiers in Robotics and AI*, 6, 102. https://doi.org/10.3389/frobt.2019.00102

Englsberger, J., Ott, C., & Albu-Schäffer, A. (2015). A computationally efficient and robust implementation of the simplified humanoid walking controller. *IEEE-RAS International Conference on Humanoid Robots*, 261-267. https://doi.org/10.1109/HUMANOIDS.2015.7363402

Hyon, S. H., & Cheng, G. (2006). Full-body compliant human–robot interface using vision and force sensing. *Autonomous Robots*, 22(4), 403-415. https://doi.org/10.1007/s10514-006-9005-9

Kajita, S., Kanehiro, F., Kaneko, K., Fujiwara, K., Harada, K., Yokoi, K., & Hirukawa, H. (2003). Biped walking pattern generation by using preview control of zero-moment point. *IEEE International Conference on Robotics and Automation*, 2, 1620-1626. https://doi.org/10.1109/ROBOT.2003.1241826

### Natural Language Processing for Robotics

Misra, D., Sung, A., & Tellex, S. (2017). Mapping natural language instructions to mobile manipulation actions with a human in the loop. *AAAI Conference on Artificial Intelligence*, 4160-4167.

Tellex, S., Walter, M. R., Teller, S., & Roy, N. (2011). Expectation-maximization for learning canonical task representations from demonstration and natural language instruction. *Proceedings of Robotics: Science and Systems*.

Veerapaneni, R., Nair, A., Pong, V., Du, M., Bhardwaj, S., Singh, S., ... & Abbeel, P. (2021). Neuro-symbolic language-guided imitation learning. *arXiv preprint arXiv:2109.00796*.

### Reinforcement Learning for Robotics

Haarnoja, T., Hartikainen, K., Abbeel, P., & Levine, S. (2017). Combining value function and policy learning for control with continuous action spaces. *Proceedings of the 34th International Conference on Machine Learning*, 70, 1447-1456.

Levine, S., Finn, C., Darrell, T., & Abbeel, P. (2016). End-to-end training of deep visuomotor policies. *Journal of Machine Learning Research*, 17(1), 1334-1373.

Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal policy optimization algorithms. *arXiv preprint arXiv:1707.06347*.

### Sim-to-Real Transfer

Kaelbling, L. P., Lozano-Pérez, T., & Wheekend, A. L. (2019). Object-oriented stochastic filtering for robotic manipulation. *arXiv preprint arXiv:1905.01914*.

Peng, X. B., Andry, A., Zhang, E., Abbeel, P., & Druckmann, S. (2021). Differentiable physics for learning and control. *Advances in Neural Information Processing Systems*, 34, 14010-14021.

Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. *IEEE/RSJ International Conference on Intelligent Robots and Systems*, 23-30. https://doi.org/10.1109/IROS.2017.8202133.

### Computer Vision for Robotics

Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You only look once: Unified, real-time object detection. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 779-788. https://doi.org/10.1109/CVPR.2016.91

Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster R-CNN: Towards real-time object detection with region proposal networks. *Advances in Neural Information Processing Systems*, 28, 91-99.

### Audio Processing and Speech Recognition

Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2022). Robust speech recognition via large-scale weak supervision. *International Conference on Machine Learning*, 18442-18461.

Zhang, Y., Kuchaiev, O., Li, B., Ginsburg, B., & Cohen, M. (2022). Streaming transformer transducer for end-to-end speech recognition. *arXiv preprint arXiv:2206.06666*.

### Safety in Robotics

Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., & Mané, D. (2016). Concrete problems in AI safety. *arXiv preprint arXiv:1606.06565*.

Soh, H., & Demiris, Y. (2014). A survey of perception systems for human–robot interaction. *IEEE Transactions on Human-Machine Systems*, 44(1), 84-98. https://doi.org/10.1109/THMS.2013.2279060

### ROS 2 and Middleware

Barry, J., & Cousins, S. (2022). The Robot Operating System 2: Design, challenges, and lessons learned. In *New Results in Control Theory and Its Applications* (pp. 153-173). Springer. https://doi.org/10.1007/978-3-030-97062-3_8

Cousins, S., Pradeep, V., Goss, C., & Sczepanski, J. (2015). Design and use paradigms for Gazebo, an open-source multi-robot simulator. *Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems*, 5574-5580. https://doi.org/10.1109/IROS.2015.7354205

### Human-Robot Interaction

Breazeal, C. (2003). *Designing sociable robots*. MIT Press.

Mutlu, B., Forlizzi, J., & Hodgins, J. (2006). A storytelling robot: Modeling and evaluation of human-like gaze behavior. *International Conference on Intelligent Robots and Systems*, 5184-5189. https://doi.org/10.1109/IROS.2006.297304

### Machine Learning and AI

Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. *Advances in Neural Information Processing Systems*, 30, 5998-6008.

### Deep Learning Frameworks

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., ... & Zheng, X. (2016). TensorFlow: Large-scale machine learning on heterogeneous systems. *Software available from tensorflow.org*.

Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S. (2019). PyTorch: An imperative style, high-performance deep learning library. *Advances in Neural Information Processing Systems*, 32, 8024-8035.

### Simulation and Physics Engines

Coumans, E., & Bai, Y. (2016). Mujoco: A physics engine for model-based control. *IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots*, 285-290. https://doi.org/10.1109/CIMSim.2016.7755424

### Navigation and Path Planning

Fox, D., Burgard, W., & Thrun, S. (1997). The dynamic window approach to collision avoidance. *IEEE Robotics & Automation Magazine*, 4(1), 23-33. https://doi.org/10.1109/100.580977

LaValle, S. M. (2006). *Planning algorithms*. Cambridge University Press. https://doi.org/10.1017/CBO9780511546877

### Isaac Platform Research

Isabella, A., Breyer, M., Novkovic, T., Solomatov, I., D'Andrea, R., & Hutter, M. (2021). Learning quadrupedal locomotion over challenging terrain. *Science Robotics*, 6(58), eabc5986. https://doi.org/10.1126/scirobotics.abc5986

NVIDIA Corporation. (2023). *Isaac Sim 5.0 Documentation*. https://docs.omniverse.nvidia.com/isaacsim/

NVIDIA Corporation. (2023). *Isaac Lab 2.3 Documentation*. https://isaac-lab.github.io/

NVIDIA Corporation. (2023). *Isaac ROS 3.0 Documentation*. https://nvidia-isaac-ros.github.io/

NVIDIA Corporation. (2023). *Isaac GR00T N1.6 Documentation*. https://www.nvidia.com/en-us/ai/research/isaac-groot/

### Vision-Language-Action Research

Agrawal, P., & Losch, J. (2023). Vision-language-action models for robotic manipulation. *arXiv preprint arXiv:2305.17142*.

Brohan, C., Dorn, J., Doshi, A., Edie, M., Garg, R., Grover, A., ... & Kollar, T. (2022). RVT: Robotic view transformation for manipulation. *arXiv preprint arXiv:2209.11133*.

Driess, D., Srivastava, S., & Toussaint, M. (2022). Language-conditioned affordance learning for robotic manipulation. *arXiv preprint arXiv:2205.12209*.

### Humanoid Robotics Research

Kajita, S., Kanehiro, F., Kaneko, K., Yokoi, K., & Hirukawa, H. (2003). The 3D linear inverted pendulum mode: A simple modeling for a biped walking pattern generation. *Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems*, 239-246. https://doi.org/10.1109/IROS.2003.1249132

Englsberger, J., Ott, C., & Albu-Schäffer, A. (2014). A computationally efficient and robust unified control framework for compliant hybrid motion/force control. *Proceedings of the 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems*, 1083-1090. https://doi.org/10.1109/IROS.2014.6942685

Sugihara, T., Yamamoto, Y., & Morisawa, M. (2012). Real-time walking pattern generation based on principal component analysis of human motion. *Advanced Robotics*, 26(15), 1723-1737. https://doi.org/10.1080/01691864.2012.718213

### Standards and Specifications

Open Robotics. (2023). *ROS 2 Humble Hawksbill Documentation*. https://docs.ros.org/en/humble/

Open Robotics. (2023). *Gazebo Harmonic Documentation*. https://gazebosim.org/

Unity Technologies. (2023). *Unity Robotics Hub Documentation*. https://github.com/Unity-Technologies/Unity-Robotics-Hub

ISO 13482:2014. *Robots and robotic devices — Personal care robots*. International Organization for Standardization.

IEEE Std 1872-2015. *IEEE Standard for On-Line Use of Electronic Components*. Institute of Electrical and Electronics Engineers.

### Additional Technical References

Bar-Cohen, Y. (Ed.). (2004). *Biologically inspired intelligent robots*. SPIE Press.

Bekey, G. A. (2005). *Autonomous robots: From biological inspiration to implementation and control*. MIT Press.

Choset, H., Lynch, K. M., Hutchinson, S., Kantor, G., Burgard, W., Kavraki, L. E., & Matarić, M. (2005). *Principles of robot motion: Theory, algorithms, and implementations*. MIT Press.

Craig, J. J. (2005). *Introduction to robotics: Mechanics and control* (3rd ed.). Pearson Prentice Hall.

Fu, K. S., Gonzalez, R. C., & Lee, C. S. G. (1987). *Robotics: Control, sensing, vision, and intelligence*. McGraw-Hill.

Khatib, O., Park, H. J., & Park, I. W. (2016). A bio-inspired multi-resolution control for highly dynamic whole-body robot behaviors. *IEEE Robotics and Automation Letters*, 1(1), 480-487. https://doi.org/10.1109/LRA.2016.2519963

Latombe, J. C. (1991). *Robot motion planning*. Kluwer Academic Publishers.

Murray, R. M., Li, Z. X., & Sastry, S. S. (1994). *A mathematical introduction to robotic manipulation*. CRC Press.

Nakanishi, J., Cory, R., Mistry, M., Peters, J., & Schaal, S. (2008). Operational space control: A theoretical and empirical comparison. *International Journal of Robotics Research*, 27(6), 737-757. https://doi.org/10.1177/0278364908091584

Siciliano, B., & Villani, L. (1999). *Robot force control*. Springer Science & Business Media.

Trinkle, J. C., & Milgram, P. (1992). Complete path planning for a planar robot with a flexible finger. *IEEE Transactions on Robotics and Automation*, 8(5), 608-618. https://doi.org/10.1109/70.163785

Whitney, D. E. (1966). Objective method for evaluating manipulator designs for assembly tasks. *Proceedings of the 6th International Symposium on Industrial Robots*, 247-262.

Yamamoto, Y., & Yun, X. (1994). Coordinating locomotion and manipulation of a mobile manipulator. *IEEE Transactions on Automatic Control*, 39(7), 1326-1342. https://doi.org/10.1109/70.298245

Zhang, Z., & Ghaffari, M. (2022). An overview of simultaneous localization and mapping: From lidar-based, visual, and deep learning perspectives. *Journal of Field Robotics*, 39(1), 3-35. https://doi.org/10.1002/rob.22015